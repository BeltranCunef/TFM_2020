{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este _notebook_ es realizar el proceso de _feature engineering_ de las variables del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../functions')\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook se expone la ingeniería de variables realizada sobre el conjunto de bases de datos proporcionados por *Home Credit*. \n",
    "\n",
    "La información proporcionada por cada una de las bases de datos es la siguiente:\n",
    "\n",
    "- __application_{train|test}.csv__: \n",
    "    - Tabla principal donde se encuentran los datos de solicitud de crédito de los clientes.\n",
    "    - Cada fila representa un préstamo.\n",
    "    \n",
    "    \n",
    "- __bureau.csv__: \n",
    "    - Información de créditos anteriores de los clientes proporcionados por instituciones financieras.\n",
    "    - Por cada crédito de la tabla principal existen tantas filas como créditos pasados reportados por la oficina de crédito (bureau) antes de la solicitud del crédito.\n",
    "    \n",
    "    \n",
    "- __bureau_balance.csv__:\n",
    "    - Balances mensuales de los créditos pasados en la oficina de crédito.\n",
    "    - Cada fila corresponde con una mensualidad de los créditos pasados.\n",
    "    \n",
    "    \n",
    "- __POS_CASH_balance.csv__: \n",
    "    - Instantaneas de los balances mensuales anteriores al momento del concesión del crédito e información histórica de créditos que los clientes adquirieron con *Home Credit*.\n",
    "    \n",
    "    \n",
    "- __credit_card_balance.csv__: \n",
    "    - Instantaneas de los balances mensuales de las tarjetas de crédito que los clientes tienen con *Home Credit*.\n",
    "    \n",
    "    \n",
    "-  __previous_application.csv__: \n",
    "    - Aplicaciones previas para créditos con *Home Credit* de clientes que tienen un préstamo en la tabla principal..\n",
    "    \n",
    "    \n",
    "- __installments_payments.csv__: \n",
    "    - Historial de pagos de créditos anteriores con *Home Credit*.\n",
    "    - Cada fila corresponde con cada pago efectuado o con cada pago no realizado en su fecha correspondiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando la información de todas las tables se agrega la información en una única base de datos mediante tranformaciones de las variables ya existentes.\n",
    "Este proceso de ingenieria se realiza para la utilización de un modelo LightGBM, algoritmo basado en arboles de decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformaciones `application_train.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/application_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos la variable de género ya que no puede usarse como información a la hora de establecer el riesgo de impago de un cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.drop('CODE_GENDER', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables categóricas binarias\n",
    "for bin_feature in ['FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "        datos[bin_feature], uniques = pd.factorize(datos[bin_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos, cat_cols = one_hot_encoder(datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la variable `DAYS_EMPLOYED` el valor 365.243 parece estár relacionado con falta de información (NA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nuevas variables (porcentajes)\n",
    "datos['DAYS_EMPLOYED_PERC'] = datos['DAYS_EMPLOYED'] / datos['DAYS_BIRTH'] \n",
    "datos['INCOME_CREDIT_PERC'] = datos['AMT_INCOME_TOTAL'] / datos['AMT_CREDIT'] \n",
    "datos['INCOME_PER_PERSON'] = datos['AMT_INCOME_TOTAL'] / datos['CNT_FAM_MEMBERS'] \n",
    "datos['ANNUITY_INCOME_PERC'] = datos['AMT_ANNUITY'] / datos['AMT_INCOME_TOTAL'] \n",
    "datos['PAYMENT_RATE'] = datos['AMT_ANNUITY'] / datos['AMT_CREDIT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformaciones de `bureau.csv` y `bureau_balance.csv``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau = pd.read_csv('../data/bureau.csv')\n",
    "bb = pd.read_csv('../data/bureau_balance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb, bb_cat = one_hot_encoder(bb, nan_as_category=True)\n",
    "bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregaciones bureau_balance\n",
    "bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
    "for col in bb_cat:\n",
    "    bb_aggregations[col] = ['mean']\n",
    "bb_agg = bb.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
    "bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "\n",
    "# Junto bureau y bureau_balance\n",
    "bureau = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "bureau.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n",
    "del bb, bb_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_aggregations = {\n",
    "    'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "    'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "    'DAYS_CREDIT_UPDATE': ['mean'],\n",
    "    'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "    'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "    'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "    'AMT_ANNUITY': ['max', 'mean'],\n",
    "    'CNT_CREDIT_PROLONG': ['sum'],\n",
    "    'MONTHS_BALANCE_MIN': ['min'],\n",
    "    'MONTHS_BALANCE_MAX': ['max'],\n",
    "    'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n",
    "}\n",
    "    \n",
    "cat_aggregations = {}\n",
    "for cat in bureau_cat: cat_aggregations[cat] = ['mean']\n",
    "for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = ['mean']\n",
    "\n",
    "bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "\n",
    "# Créditos activos en bureau agregaciones de variables numéricas\n",
    "active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
    "active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
    "del active, active_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
    "closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n",
    "del closed, closed_agg, bureau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformaciones de previous_applications.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = pd.read_csv('../data/previous_application.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev, cat_cols = one_hot_encoder(prev, nan_as_category= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sustitucion del valor 365243 por NA\n",
    "prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
    "\n",
    "# Nueva variable porcentaje del prestamo concedido sobre el pedido\n",
    "prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "\n",
    "num_aggregations = {\n",
    "    'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "    'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "    'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "    'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "    'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "    'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "    'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "    'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "    'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "    'CNT_PAYMENT': ['mean', 'sum'],\n",
    "}\n",
    "\n",
    "cat_aggregations = {}\n",
    "for cat in cat_cols:\n",
    "    cat_aggregations[cat] = ['mean']\n",
    "\n",
    "prev_agg = prev.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "\n",
    "# Previous Applications agregaciones de las variables numéricas sobre las aplicaciones aprovadas\n",
    "approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "# Previous Applications agregaciones de las variables numéricas sobre las aplicaciones denegadas\n",
    "refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
    "del refused, refused_agg, approved, approved_agg, prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformaciones POS_CASH_balance.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = pd.read_csv('../data/POS_CASH_balance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, cat_cols = one_hot_encoder(pos, nan_as_category= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregations = {\n",
    "    'MONTHS_BALANCE': ['max', 'mean', 'size'],\n",
    "    'SK_DPD': ['max', 'mean'],\n",
    "    'SK_DPD_DEF': ['max', 'mean']\n",
    "}\n",
    "\n",
    "for cat in cat_cols:\n",
    "    aggregations[cat] = ['mean']\n",
    "\n",
    "pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations)\n",
    "pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "\n",
    "# Numero de cuentas\n",
    "pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n",
    "del pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformaciones installments_payments.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = pd.read_csv('../data/installments_payments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins, cat_cols = one_hot_encoder(ins, nan_as_category= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porcentaje pagado sobre la cuota mensual y diferencia entre la cuota y lo pagado\n",
    "ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
    "ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
    "\n",
    "# Days past due y days before due \n",
    "ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
    "ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
    "\n",
    "# Valores positivos\n",
    "ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "\n",
    "aggregations = {\n",
    "    'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "    'DPD': ['max', 'mean', 'sum'],\n",
    "    'DBD': ['max', 'mean', 'sum'],\n",
    "    'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
    "    'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
    "    'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "    'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "    'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n",
    "}\n",
    "for cat in cat_cols:\n",
    "    aggregations[cat] = ['mean']\n",
    "ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n",
    "ins_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "\n",
    "# Numero de cuentas en installments\n",
    "ins_agg['INSTAL_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
    "del ins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformaciones credit_card_balance.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = pd.read_csv('../data/credit_card_balance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc, cat_cols = one_hot_encoder(cc, nan_as_category= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n",
    "cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
    "cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "\n",
    "# Numero de tarjetas de crédito\n",
    "cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n",
    "del cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Union de los dataframes con la variable `SK_ID_CURR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = datos.join(bureau_agg, how='left', on='SK_ID_CURR')\n",
    "datos = datos.join(prev_agg, how='left', on='SK_ID_CURR')\n",
    "datos = datos.join(pos_agg, how='left', on='SK_ID_CURR')\n",
    "datos = datos.join(ins_agg, how='left', on='SK_ID_CURR')\n",
    "datos = datos.join(cc_agg, how='left', on='SK_ID_CURR')\n",
    "del bureau_agg, prev_agg, pos_agg, ins_agg, cc_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.drop('SK_ID_CURR', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion de los nombres de las columnas con caracteres que no admite LightGBM\n",
    "datos = datos.rename(columns = lambda x: x.replace(':', '').replace(',', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimino las variables que solo tienen un único valor\n",
    "null_features = []\n",
    "\n",
    "for var in datos.columns:\n",
    "    if datos[f'{var}'].nunique() == 1:\n",
    "        null_features.append(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(null_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.drop(null_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.to_csv('../data/datos_procesados.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
